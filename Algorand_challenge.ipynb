{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GEQYjMoBIJz6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16fdd2d1-066d-410e-bb69-dc56e09efa46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.4 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hReady. Folders: /data, /model, /out\n"
          ]
        }
      ],
      "source": [
        "# Colab setup: install minimal deps\n",
        "!pip -q install numpy pandas pynacl\n",
        "\n",
        "# Folders\n",
        "import os, json, time, math, base64, hashlib, random\n",
        "from datetime import datetime, timedelta\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "os.makedirs(\"model\", exist_ok=True)\n",
        "os.makedirs(\"out\", exist_ok=True)\n",
        "\n",
        "print(\"Ready. Folders: /data, /model, /out\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json, hashlib, time\n",
        "from typing import Dict, Any\n",
        "\n",
        "def now_ts() -> int:\n",
        "    return int(time.time())\n",
        "\n",
        "def sha256_hex(b: bytes) -> str:\n",
        "    return hashlib.sha256(b).hexdigest()\n",
        "\n",
        "def canonical_json(d: Dict[str, Any]) -> bytes:\n",
        "    # Stable, minimal JSON representation for signing\n",
        "    return json.dumps(d, separators=(\",\", \":\"), sort_keys=True).encode()\n",
        "\n",
        "def model_hash(weights: Dict[str, Any]) -> str:\n",
        "    blob = canonical_json({\"w\": [float(x) for x in weights[\"w\"]], \"b\": float(weights[\"b\"])})\n",
        "    return \"0x\" + sha256_hex(blob)\n",
        "\n",
        "def make_pseudo_cid(payload: Dict[str, Any]) -> str:\n",
        "    # Local, IPFS-free stand-in (good enough for hackathon demos)\n",
        "    return f\"cid_sha256:{sha256_hex(canonical_json(payload))}\""
      ],
      "metadata": {
        "id": "8f7CgWxHTHWV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def load_cashflow_csv(path: str) -> pd.DataFrame:\n",
        "    df = pd.read_csv(path, parse_dates=[\"date\"])\n",
        "    df = df.sort_values(\"date\").reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "def daily_series(df: pd.DataFrame, days: int = 90) -> pd.DataFrame:\n",
        "    end = df[\"date\"].max()\n",
        "    start = end - pd.Timedelta(days=days-1)\n",
        "    rng = pd.date_range(start, end, freq=\"D\")\n",
        "    s = df.set_index(\"date\")[\"amount\"].groupby(pd.Grouper(freq=\"D\")).sum().reindex(rng, fill_value=0.0)\n",
        "    return pd.DataFrame({\"date\": rng, \"amount\": s.values})\n",
        "\n",
        "def max_drawdown(series: np.ndarray) -> float:\n",
        "    cum = series.cumsum()\n",
        "    peak = np.maximum.accumulate(cum)\n",
        "    return float((peak - cum).max())\n",
        "\n",
        "def periodicity_score(series: np.ndarray) -> float:\n",
        "    # crude autocorr at lags 14, 28, 30 (pay cycles)\n",
        "    def acf(x, lag):\n",
        "        x1 = x[:-lag]; x2 = x[lag:]\n",
        "        if x1.std() < 1e-8 or x2.std() < 1e-8: return 0.0\n",
        "        return float(np.corrcoef(x1, x2)[0,1])\n",
        "    if len(series) < 31: return 0.0\n",
        "    return max(0.0, max(acf(series, l) for l in [14,28,30]))\n",
        "\n",
        "def shock_recovery(series: np.ndarray) -> float:\n",
        "    # Approx. steps to recover from 1-σ negative shock; normalized to [0,1]\n",
        "    x = series.copy()\n",
        "    if x.std() < 1e-8: return 1.0\n",
        "    shock = -x.std()\n",
        "    bal = x.cumsum(); target = bal[-1]\n",
        "    bal2 = bal + shock\n",
        "    rec = next((i+1 for i in range(len(bal2)) if bal2[i] >= target), len(bal2))\n",
        "    return float(min(rec / len(bal2), 1.0))\n",
        "\n",
        "def feature_vector(df: pd.DataFrame, window_days: int = 90) -> np.ndarray:\n",
        "    ds = daily_series(df, days=window_days)\n",
        "    x = ds[\"amount\"].values.astype(float)\n",
        "    inflow  = np.clip(x, 0, None)\n",
        "    outflow = np.clip(-x, 0, None)\n",
        "    feats = []\n",
        "    # Level & volatility\n",
        "    feats += [inflow.mean(), inflow.std() + 1e-6, outflow.mean(), outflow.std() + 1e-6]\n",
        "    # Net and volatility ratio\n",
        "    net = inflow.mean() - outflow.mean()\n",
        "    feats += [net, (outflow.std() / (inflow.std() + 1e-6))]\n",
        "    # Drawdown on cumulative\n",
        "    feats += [max_drawdown(x)]\n",
        "    # Periodicity\n",
        "    feats += [periodicity_score(inflow - outflow)]\n",
        "    # Shock recovery\n",
        "    feats += [shock_recovery(x)]\n",
        "    # Skewness / kurtosis proxies\n",
        "    feats += [float(pd.Series(x).skew()), float(pd.Series(x).kurt())]\n",
        "    feats = np.array(feats, dtype=float)\n",
        "    # log-scale money-like magnitudes for stability\n",
        "    money_idx = [0,1,2,3,4,5,6]\n",
        "    feats[money_idx] = np.sign(feats[money_idx]) * np.log1p(np.abs(feats[money_idx]))\n",
        "    return feats  # shape (p,)\n"
      ],
      "metadata": {
        "id": "qon2ATZJTNV4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from typing import Dict, Tuple, List\n",
        "\n",
        "def init_model(p: int, seed: int = 0) -> Dict[str, np.ndarray]:\n",
        "    rng = np.random.default_rng(seed)\n",
        "    w = rng.normal(0, 0.05, size=(p,)).astype(float)\n",
        "    b = 0.0\n",
        "    return {\"w\": w, \"b\": b}\n",
        "\n",
        "def sigmoid(z): return 1.0 / (1.0 + np.exp(-z))\n",
        "\n",
        "def predict_proba(weights, X):\n",
        "    return sigmoid(X @ weights[\"w\"] + weights[\"b\"])\n",
        "\n",
        "def loss_and_grad(weights, X, y, l2=1e-4):\n",
        "    p = predict_proba(weights, X)\n",
        "    eps = 1e-8\n",
        "    loss = -(y*np.log(p+eps)+(1-y)*np.log(1-p+eps)).mean() + 0.5*l2*np.sum(weights[\"w\"]**2)\n",
        "    g = (p - y) / len(y)\n",
        "    grad_w = X.T @ g + l2*weights[\"w\"]\n",
        "    grad_b = g.sum()\n",
        "    return float(loss), {\"w\": grad_w, \"b\": grad_b}\n",
        "\n",
        "def clip_grad(grad, max_norm=1.0):\n",
        "    norm = float(np.sqrt((grad[\"w\"]**2).sum() + grad[\"b\"]**2))\n",
        "    if norm > max_norm:\n",
        "        scale = max_norm / (norm + 1e-8)\n",
        "        grad[\"w\"] *= scale; grad[\"b\"] *= scale\n",
        "    return grad\n",
        "\n",
        "def add_noise(grad, sigma=0.0, rng=None):\n",
        "    if sigma <= 0: return grad\n",
        "    rng = rng or np.random.default_rng()\n",
        "    grad[\"w\"] = grad[\"w\"] + rng.normal(0, sigma, size=grad[\"w\"].shape)\n",
        "    grad[\"b\"] = grad[\"b\"] + rng.normal(0, sigma)\n",
        "    return grad\n",
        "\n",
        "def fedavg_round(global_weights, client_data: List[Tuple[np.ndarray, np.ndarray]],\n",
        "                 lr=0.05, l2=1e-4, clip=1.0, sigma=0.05, rng=None):\n",
        "    grads, losses = [], []\n",
        "    for (X, y) in client_data:\n",
        "        loss, grad = loss_and_grad(global_weights, X, y, l2=l2)\n",
        "        grad = clip_grad(grad, max_norm=clip)\n",
        "        grad = add_noise(grad, sigma=sigma, rng=rng)\n",
        "        grads.append(grad); losses.append(loss)\n",
        "    g_w = sum(g[\"w\"] for g in grads) / len(grads)\n",
        "    g_b = sum(g[\"b\"] for g in grads) / len(grads)\n",
        "    return {\"w\": global_weights[\"w\"] - lr*g_w, \"b\": global_weights[\"b\"] - lr*g_b}, float(np.mean(losses))"
      ],
      "metadata": {
        "id": "4SZ1g_lTTQOJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd\n",
        "\n",
        "def simulate_client(days=120, seed=0, risk=0.3):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    start = pd.Timestamp.today().normalize() - pd.Timedelta(days=days)\n",
        "    dates = [start + pd.Timedelta(days=i+1) for i in range(days)]\n",
        "    # inflow: periodic pay + small noise\n",
        "    pay_period = rng.choice([14, 28, 30], p=[0.2,0.5,0.3])\n",
        "    inflow = np.zeros(days)\n",
        "    for i in range(days):\n",
        "        if (i % pay_period) == 0:\n",
        "            inflow[i] += rng.normal(100, 20)\n",
        "        inflow[i] += max(0, rng.normal(5, 5))\n",
        "    # outflow: daily spend + shocks depending on risk\n",
        "    outflow = np.maximum(0, rng.normal(5 + 20*risk, 5 + 10*risk, size=days))\n",
        "    if rng.random() < 0.4:\n",
        "        j = rng.integers(10, days-10)\n",
        "        outflow[j:j+3] += rng.normal(60, 20, size=3)\n",
        "    amounts = inflow - outflow\n",
        "    df = pd.DataFrame({\"date\": dates, \"amount\": amounts})\n",
        "    # label proxy: default in next 30d ~ f(vol, drawdown, risk)\n",
        "    bal = df[\"amount\"].cumsum()\n",
        "    vol = float(np.std(df[\"amount\"]))\n",
        "    dd  = float(np.max(np.maximum.accumulate(bal) - bal))\n",
        "    pd_prob = 1/(1+np.exp(-( -0.5 + 0.03*vol + 0.02*dd + 1.2*risk )))\n",
        "    label = 1 if rng.random() < pd_prob else 0\n",
        "    return df, int(label)\n",
        "\n",
        "# Generate a small federation\n",
        "def generate_dataset(n_clients=5, days=120, seed=42, outdir=\"data\"):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    metas = []\n",
        "    for i in range(1, n_clients+1):\n",
        "        risk = float(rng.uniform(0.05, 0.6))\n",
        "        df, label = simulate_client(days=days, seed=seed+i, risk=risk)\n",
        "        path = f\"{outdir}/client_{i}.csv\"\n",
        "        df.to_csv(path, index=False)\n",
        "        metas.append({\"client_id\": i, \"path\": path, \"label\": label, \"risk\": risk})\n",
        "    pd.DataFrame(metas).to_csv(f\"{outdir}/meta.csv\", index=False)\n",
        "    print(f\"Created {n_clients} client CSVs in /data and meta.csv\")\n",
        "\n",
        "# Run generator\n",
        "generate_dataset(n_clients=5, days=120, seed=42, outdir=\"data\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMQYP96UTUaE",
        "outputId": "1ec038ab-49e6-405d-c3f8-11cbfd7c025d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created 5 client CSVs in /data and meta.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, numpy as np, pandas as pd\n",
        "\n",
        "def load_clients(datadir=\"data\"):\n",
        "    meta = pd.read_csv(f\"{datadir}/meta.csv\")\n",
        "    Xs, ys = [], []\n",
        "    for _, row in meta.iterrows():\n",
        "        df = load_cashflow_csv(row[\"path\"])\n",
        "        x = feature_vector(df)\n",
        "        y = np.array([row[\"label\"]], dtype=float)  # one label per client\n",
        "        Xs.append(x.reshape(1,-1))\n",
        "        ys.append(y)\n",
        "    return Xs, ys\n",
        "\n",
        "def evaluate(W, Xs, ys):\n",
        "    X = np.vstack(Xs)\n",
        "    y = np.concatenate(ys)\n",
        "    p = predict_proba(W, X).reshape(-1)\n",
        "    brier = float(np.mean((p - y)**2))\n",
        "    acc = float(np.mean(((p>=0.5).astype(int) == y)))\n",
        "    return {\"Brier\": brier, \"Acc\": acc}\n",
        "\n",
        "# Train\n",
        "Xs, ys = load_clients(\"data\")\n",
        "p = Xs[0].shape[1]\n",
        "W = init_model(p, seed=0)\n",
        "losses = []\n",
        "rng = np.random.default_rng(0)\n",
        "rounds, lr, l2, clip, sigma = 8, 0.1, 1e-4, 1.0, 0.05\n",
        "\n",
        "for r in range(1, rounds+1):\n",
        "    W, loss = fedavg_round(W, list(zip(Xs, ys)), lr=lr, l2=l2, clip=clip, sigma=sigma, rng=rng)\n",
        "    losses.append(loss)\n",
        "    print(f\"Round {r}: loss={loss:.4f}\")\n",
        "\n",
        "metrics = evaluate(W, Xs, ys)\n",
        "print(\"Metrics:\", metrics)\n",
        "\n",
        "# Save global model\n",
        "out = {\n",
        "  \"weights\": {\"w\": W[\"w\"].tolist(), \"b\": float(W[\"b\"])},\n",
        "  \"metrics\": metrics,\n",
        "  \"rounds\": rounds,\n",
        "  \"dp_sigma\": sigma,\n",
        "  \"clip\": clip,\n",
        "  \"lr\": lr,\n",
        "  \"l2\": l2\n",
        "}\n",
        "out[\"model_hash\"] = sha256_hex(json.dumps(out[\"weights\"], sort_keys=True).encode())\n",
        "os.makedirs(\"model\", exist_ok=True)\n",
        "with open(\"model/global_model.json\", \"w\") as f:\n",
        "    json.dump(out, f, indent=2)\n",
        "print(\"Saved model → model/global_model.json\")\n",
        "print(\"model_hash = 0x\" + out[\"model_hash\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSyoviMpTX_b",
        "outputId": "e410bed6-b4c9-4eb4-d1fc-ecff99ea937a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Round 1: loss=0.7543\n",
            "Round 2: loss=0.1989\n",
            "Round 3: loss=0.0490\n",
            "Round 4: loss=0.0190\n",
            "Round 5: loss=0.0127\n",
            "Round 6: loss=0.0099\n",
            "Round 7: loss=0.0086\n",
            "Round 8: loss=0.0075\n",
            "Metrics: {'Brier': 9.280123651198106e-05, 'Acc': 1.0}\n",
            "Saved model → model/global_model.json\n",
            "model_hash = 0x9ca8681d80274bc25c537d0193a02d92f8ac08e2d78204ac033040edbb72b542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json, time, base64, numpy as np, pandas as pd\n",
        "from nacl.signing import SigningKey, VerifyKey\n",
        "\n",
        "def load_model(path=\"model/global_model.json\"):\n",
        "    with open(path, \"r\") as f:\n",
        "        obj = json.load(f)\n",
        "    w = np.array(obj[\"weights\"][\"w\"], dtype=float)\n",
        "    b = float(obj[\"weights\"][\"b\"])\n",
        "    return {\"w\": w, \"b\": b}, obj\n",
        "\n",
        "def score_csv(csv_path: str, model_path=\"model/global_model.json\"):\n",
        "    W, meta = load_model(model_path)\n",
        "    df = load_cashflow_csv(csv_path)\n",
        "    x = feature_vector(df).reshape(1,-1)\n",
        "    pd_prob = float(sigmoid(x @ W[\"w\"] + W[\"b\"]))  # P(default in 30d)\n",
        "    cri = float(1.0 - pd_prob)                     # score ∈ [0,1]\n",
        "    return cri, pd_prob, meta\n",
        "\n",
        "# Deterministic signer (seeded for reproducibility in demos)\n",
        "seed_bytes = hashlib.sha256(b\"demo_attestor_seed\").digest()\n",
        "SK = SigningKey(seed_bytes)\n",
        "PK = SK.verify_key\n",
        "\n",
        "# Choose a client file to score (client_1.csv) and a demo wallet address\n",
        "addr = \"ADDR_DEMO_ABC123\"\n",
        "csv_path = \"data/client_1.csv\"\n",
        "epoch = 1\n",
        "metric_id = \"CRI\"\n",
        "\n",
        "score, pd_prob, meta = score_csv(csv_path)\n",
        "att = {\n",
        "  \"attestation_id\": f\"att-{sha256_hex((addr + csv_path + str(now_ts())).encode())[:16]}\",\n",
        "  \"subject_type\": \"user_wallet\",\n",
        "  \"subject_id\": addr,\n",
        "  \"metric_id\": metric_id,\n",
        "  \"score\": round(score, 6),\n",
        "  \"uncertainty\": 0.08,           # placeholder\n",
        "  \"epoch\": epoch,\n",
        "  \"model_hash\": \"0x\" + meta[\"model_hash\"],\n",
        "  \"dp_epsilon\": 1.2,             # config placeholder\n",
        "  \"dp_delta\": 1e-5,\n",
        "  \"consortium_id\": \"demo\",\n",
        "  \"metrics\": meta.get(\"metrics\", {}),\n",
        "  \"issued_at\": now_ts(),\n",
        "  \"expires_at\": now_ts() + 30*24*3600,\n",
        "  \"artifact_cids\": {\"model_card\": \"\", \"explain\": \"\"}\n",
        "}\n",
        "\n",
        "# Sign canonical JSON hash with Ed25519 (Algorand-compatible curve)\n",
        "preimage = canonical_json(att)\n",
        "h = hashlib.sha256(preimage).digest()\n",
        "sig = SK.sign(h).signature\n",
        "sig_b64 = base64.b64encode(sig).decode()\n",
        "pk_b64  = base64.b64encode(bytes(PK)).decode()\n",
        "\n",
        "cid = make_pseudo_cid(att)  # local pseudo-CID for demos\n",
        "\n",
        "bundle = {\n",
        "  \"attestation\": att,\n",
        "  \"cid\": cid,\n",
        "  \"sig_b64\": sig_b64,\n",
        "  \"attestor_pk_b64\": pk_b64,\n",
        "  \"app_args\": {\n",
        "    \"subject\": addr,\n",
        "    \"metric\": metric_id,\n",
        "    \"score_u16\": int(round(score * 10000)),\n",
        "    \"cid\": cid,\n",
        "    \"epoch\": epoch,\n",
        "    \"sig_b64\": sig_b64\n",
        "  }\n",
        "}\n",
        "\n",
        "with open(f\"out/attestation_{metric_id}_{addr[:6]}.json\", \"w\") as f:\n",
        "    json.dump(bundle, f, indent=2)\n",
        "\n",
        "print(json.dumps(bundle[\"attestation\"], indent=2))\n",
        "print(\"\\nApp args (copy to contract call):\")\n",
        "print(json.dumps(bundle[\"app_args\"], indent=2))\n",
        "print(\"\\nSaved →\", f\"out/attestation_{metric_id}_{addr[:6]}.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y20kcd9oTbJo",
        "outputId": "6207269c-1827-4f79-e3af-e82066858e92"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"attestation_id\": \"att-852e32ed26f0b1bf\",\n",
            "  \"subject_type\": \"user_wallet\",\n",
            "  \"subject_id\": \"ADDR_DEMO_ABC123\",\n",
            "  \"metric_id\": \"CRI\",\n",
            "  \"score\": 0.00159,\n",
            "  \"uncertainty\": 0.08,\n",
            "  \"epoch\": 1,\n",
            "  \"model_hash\": \"0x9ca8681d80274bc25c537d0193a02d92f8ac08e2d78204ac033040edbb72b542\",\n",
            "  \"dp_epsilon\": 1.2,\n",
            "  \"dp_delta\": 1e-05,\n",
            "  \"consortium_id\": \"demo\",\n",
            "  \"metrics\": {\n",
            "    \"Brier\": 9.280123651198106e-05,\n",
            "    \"Acc\": 1.0\n",
            "  },\n",
            "  \"issued_at\": 1760832795,\n",
            "  \"expires_at\": 1763424795,\n",
            "  \"artifact_cids\": {\n",
            "    \"model_card\": \"\",\n",
            "    \"explain\": \"\"\n",
            "  }\n",
            "}\n",
            "\n",
            "App args (copy to contract call):\n",
            "{\n",
            "  \"subject\": \"ADDR_DEMO_ABC123\",\n",
            "  \"metric\": \"CRI\",\n",
            "  \"score_u16\": 16,\n",
            "  \"cid\": \"cid_sha256:539447937eaed7e1d80b5e7deaaeba1a56002356449e9c9b4239793756e89c8f\",\n",
            "  \"epoch\": 1,\n",
            "  \"sig_b64\": \"Q5UGyeWt6vvdVspul2d/fiX84ocqfzVWMJLyjDI/RE6DubPYn+ylW+P+Gc5myDR2VB8O8h0Whj3V66Ox8U3FAw==\"\n",
            "}\n",
            "\n",
            "Saved → out/attestation_CRI_ADDR_D.json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-853037182.py:15: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  pd_prob = float(sigmoid(x @ W[\"w\"] + W[\"b\"]))  # P(default in 30d)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nacl.signing import VerifyKey\n",
        "\n",
        "with open(f\"out/attestation_{metric_id}_{addr[:6]}.json\", \"r\") as f:\n",
        "    b = json.load(f)\n",
        "\n",
        "payload = b[\"attestation\"]\n",
        "sig_b64 = b[\"sig_b64\"]\n",
        "pk_b64  = b[\"attestor_pk_b64\"]\n",
        "\n",
        "canonical = canonical_json(payload)\n",
        "h = hashlib.sha256(canonical).digest()\n",
        "vk = VerifyKey(base64.b64decode(pk_b64))\n",
        "\n",
        "try:\n",
        "    vk.verify(h, base64.b64decode(sig_b64))\n",
        "    print(\"✅ Signature valid over canonical JSON hash.\")\n",
        "except Exception as e:\n",
        "    print(\"❌ Invalid signature:\", e)\n",
        "\n",
        "print(\"\\nPseudo-CID (for storage demo):\", b[\"cid\"])\n",
        "print(\"Score_u16 (fixed-point):\", b[\"app_args\"][\"score_u16\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9g4GkFTTf9s",
        "outputId": "d274dc72-8bd5-4d9e-88a8-3fbadc02115a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Signature valid over canonical JSON hash.\n",
            "\n",
            "Pseudo-CID (for storage demo): cid_sha256:539447937eaed7e1d80b5e7deaaeba1a56002356449e9c9b4239793756e89c8f\n",
            "Score_u16 (fixed-point): 16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Self-contained demo: simulate data, train a federated logistic model, print a user's CRI score and contract app_args.\n",
        "import numpy as np, pandas as pd, hashlib, json, time\n",
        "\n",
        "# ---- Data simulation ----\n",
        "def simulate_client(days=120, seed=0, risk=0.3):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    start = pd.Timestamp.today().normalize() - pd.Timedelta(days=days)\n",
        "    dates = [start + pd.Timedelta(days=i+1) for i in range(days)]\n",
        "    pay_period = rng.choice([14, 28, 30], p=[0.2,0.5,0.3])\n",
        "    inflow = np.zeros(days)\n",
        "    for i in range(days):\n",
        "        if (i % pay_period) == 0:\n",
        "            inflow[i] += rng.normal(100, 20)\n",
        "        inflow[i] += max(0, rng.normal(5, 5))\n",
        "    outflow = np.maximum(0, rng.normal(5 + 20*risk, 5 + 10*risk, size=days))\n",
        "    if rng.random() < 0.4:\n",
        "        j = rng.integers(10, days-10)\n",
        "        outflow[j:j+3] += rng.normal(60, 20, size=3)\n",
        "    amounts = inflow - outflow\n",
        "    df = pd.DataFrame({\"date\": dates, \"amount\": amounts})\n",
        "    bal = df[\"amount\"].cumsum()\n",
        "    vol = float(np.std(df[\"amount\"]))\n",
        "    dd  = float(np.max(np.maximum.accumulate(bal) - bal))\n",
        "    pd_prob = 1/(1+np.exp(-( -0.5 + 0.03*vol + 0.02*dd + 1.2*risk )))\n",
        "    label = 1 if rng.random() < pd_prob else 0\n",
        "    return df, int(label)\n",
        "\n",
        "# ---- Feature engineering ----\n",
        "def daily_series(df: pd.DataFrame, days: int = 90) -> pd.DataFrame:\n",
        "    end = df[\"date\"].max()\n",
        "    start = end - pd.Timedelta(days=days-1)\n",
        "    rng = pd.date_range(start, end, freq=\"D\")\n",
        "    s = df.set_index(\"date\")[\"amount\"].groupby(pd.Grouper(freq=\"D\")).sum().reindex(rng, fill_value=0.0)\n",
        "    return pd.DataFrame({\"date\": rng, \"amount\": s.values})\n",
        "\n",
        "def max_drawdown(series: np.ndarray) -> float:\n",
        "    cum = series.cumsum()\n",
        "    peak = np.maximum.accumulate(cum)\n",
        "    return float((peak - cum).max())\n",
        "\n",
        "def periodicity_score(series: np.ndarray) -> float:\n",
        "    def acf(x, lag):\n",
        "        x1 = x[:-lag]; x2 = x[lag:]\n",
        "        if x1.std() < 1e-8 or x2.std() < 1e-8: return 0.0\n",
        "        return float(np.corrcoef(x1, x2)[0,1])\n",
        "    if len(series) < 31: return 0.0\n",
        "    return max(0.0, max(acf(series, l) for l in [14,28,30]))\n",
        "\n",
        "def shock_recovery(series: np.ndarray) -> float:\n",
        "    x = series.copy()\n",
        "    if x.std() < 1e-8: return 1.0\n",
        "    shock = -x.std()\n",
        "    bal = x.cumsum(); target = bal[-1]\n",
        "    bal2 = bal + shock\n",
        "    rec = next((i+1 for i in range(len(bal2)) if bal2[i] >= target), len(bal2))\n",
        "    return float(min(rec / len(bal2), 1.0))\n",
        "\n",
        "def feature_vector(df: pd.DataFrame, window_days: int = 90) -> np.ndarray:\n",
        "    ds = daily_series(df, days=window_days)\n",
        "    x = ds[\"amount\"].values.astype(float)\n",
        "    inflow  = np.clip(x, 0, None)\n",
        "    outflow = np.clip(-x, 0, None)\n",
        "    feats = []\n",
        "    feats += [inflow.mean(), inflow.std() + 1e-6, outflow.mean(), outflow.std() + 1e-6]\n",
        "    net = inflow.mean() - outflow.mean()\n",
        "    feats += [net, (outflow.std() / (inflow.std() + 1e-6))]\n",
        "    feats += [max_drawdown(x)]\n",
        "    feats += [periodicity_score(inflow - outflow)]\n",
        "    feats += [shock_recovery(x)]\n",
        "    feats += [float(pd.Series(x).skew()), float(pd.Series(x).kurt())]\n",
        "    feats = np.array(feats, dtype=float)\n",
        "    money_idx = [0,1,2,3,4,5,6]\n",
        "    feats[money_idx] = np.sign(feats[money_idx]) * np.log1p(np.abs(feats[money_idx]))\n",
        "    return feats\n",
        "\n",
        "# ---- Federated logistic regression ----\n",
        "def init_model(p: int, seed: int = 0):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    return {\"w\": rng.normal(0, 0.05, size=p).astype(float), \"b\": 0.0}\n",
        "\n",
        "def sigmoid(z): return 1.0 / (1.0 + np.exp(-z))\n",
        "def predict_proba(W, X): return sigmoid(X @ W[\"w\"] + W[\"b\"])\n",
        "\n",
        "def loss_and_grad(W, X, y, l2=1e-4):\n",
        "    p = predict_proba(W, X); eps=1e-8\n",
        "    loss = -(y*np.log(p+eps)+(1-y)*np.log(1-p+eps)).mean() + 0.5*l2*np.sum(W[\"w\"]**2)\n",
        "    g = (p - y) / len(y)\n",
        "    return float(loss), {\"w\": X.T @ g + l2*W[\"w\"], \"b\": g.sum()}\n",
        "\n",
        "def clip_grad(g, max_norm=1.0):\n",
        "    norm = float(np.sqrt((g[\"w\"]**2).sum() + g[\"b\"]**2))\n",
        "    if norm > max_norm:\n",
        "        scale = max_norm / (norm + 1e-8)\n",
        "        g[\"w\"] *= scale; g[\"b\"] *= scale\n",
        "    return g\n",
        "\n",
        "def add_noise(g, sigma=0.05, rng=None):\n",
        "    if sigma <= 0: return g\n",
        "    rng = rng or np.random.default_rng()\n",
        "    g[\"w\"] = g[\"w\"] + rng.normal(0, sigma, size=g[\"w\"].shape)\n",
        "    g[\"b\"] = g[\"b\"] + rng.normal(0, sigma)\n",
        "    return g\n",
        "\n",
        "def fedavg_round(W, client_data, lr=0.1, l2=1e-4, clip=1.0, sigma=0.05, rng=None):\n",
        "    grads, losses = [], []\n",
        "    for (X, y) in client_data:\n",
        "        loss, g = loss_and_grad(W, X, y, l2=l2)\n",
        "        g = clip_grad(g, max_norm=clip)\n",
        "        g = add_noise(g, sigma=sigma, rng=rng)\n",
        "        grads.append(g); losses.append(loss)\n",
        "    g_w = sum(g[\"w\"] for g in grads) / len(grads)\n",
        "    g_b = sum(g[\"b\"] for g in grads) / len(grads)\n",
        "    return {\"w\": W[\"w\"] - lr*g_w, \"b\": W[\"b\"] - lr*g_b}, float(np.mean(losses))\n",
        "\n",
        "# ---- Simulate federation and train ----\n",
        "clients = [simulate_client(days=120, seed=100+i, risk=0.15+0.1*i) for i in range(5)]\n",
        "Xs, ys = [], []\n",
        "for df, label in clients:\n",
        "    Xs.append(feature_vector(df).reshape(1,-1))\n",
        "    ys.append(np.array([label], dtype=float))\n",
        "\n",
        "W = init_model(Xs[0].shape[1], seed=0)\n",
        "rng = np.random.default_rng(0)\n",
        "for r in range(8):\n",
        "    W, loss = fedavg_round(W, list(zip(Xs, ys)), lr=0.1, l2=1e-4, clip=1.0, sigma=0.05, rng=rng)\n",
        "\n",
        "# ---- Score user 1 ----\n",
        "pd_prob = float(predict_proba(W, Xs[0])[0])   # P(default)\n",
        "cri = 1.0 - pd_prob\n",
        "\n",
        "addr = \"ADDR_DEMO_ABC123\"\n",
        "metric = \"CRI\"\n",
        "app_args = {\n",
        "    \"subject\": addr,\n",
        "    \"metric\": metric,\n",
        "    \"score_u16\": int(round(cri * 10000)),\n",
        "    \"cid\": f\"cid_demo_user1_{int(cri*10000)}\",\n",
        "    \"epoch\": 1,\n",
        "    \"sig_b64\": \"\"\n",
        "}\n",
        "\n",
        "print({\n",
        "    \"user_address\": addr,\n",
        "    \"prob_default_30d\": round(pd_prob, 4),\n",
        "    \"CRI_score_0to1\": round(cri, 4),\n",
        "    \"CRI_score_0to100\": round(cri*100, 2),\n",
        "    \"app_args\": app_args\n",
        "})\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsNQ1e_eUATz",
        "outputId": "09454764-6f87-47b7-e3b8-925ed5c1f3ef"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'user_address': 'ADDR_DEMO_ABC123', 'prob_default_30d': 0.9994, 'CRI_score_0to1': 0.0006, 'CRI_score_0to100': 0.06, 'app_args': {'subject': 'ADDR_DEMO_ABC123', 'metric': 'CRI', 'score_u16': 6, 'cid': 'cid_demo_user1_6', 'epoch': 1, 'sig_b64': ''}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, hashlib\n",
        "os.makedirs(\"model\", exist_ok=True)\n",
        "\n",
        "out = {\n",
        "  \"weights\": {\"w\": W[\"w\"].tolist(), \"b\": float(W[\"b\"])},\n",
        "  \"metrics\": metrics, # e.g., {\"Brier\": ..., \"Acc\": ...}\n",
        "  \"rounds\": rounds,\n",
        "  \"dp_sigma\": sigma, \"clip\": clip, \"lr\": lr, \"l2\": l2\n",
        "}\n",
        "out[\"model_hash\"] = hashlib.sha256(json.dumps(out[\"weights\"], sort_keys=True).encode()).hexdigest()\n",
        "with open(\"model/global_model.json\",\"w\") as f:\n",
        "    json.dump(out, f, indent=2)\n",
        "\n",
        "print(\"Saved model → model/global_model.json\")\n"
      ],
      "metadata": {
        "id": "-d8hW8FFUBf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "054276cf-5b48-4bf9-dcf3-21c7b1f1d179"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model → model/global_model.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NhdHoj9J9Nu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jQ0n2Etf9N8o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}